# NLP_Assignment2


## Tokenizer Training:

| Dataset Size (in MBs) | Fertility Score | Tokenizer |
|------------------------|-----------------|-----------|
| 500                    | 1.062340199     | Tokenizer 1 |
| 800                    | 1.061760271     | Tokenizer 2 |
| 1000                   | 1.061677823     | Tokenizer 3 |
| 1200                   | 1.061477151     | Tokenizer 4 |
| 1500                   | 1.061219034     | Tokenizer 5 |


##  Model Training



### Individual Contributions of Group 

| Name             | Roll No. | Contribution                     |
|------------------|----------|----------------------------------|
| Husain Malwat    | 21110117 |                                  |
| Amey Rangari     | 21110177 |                                  |
| Netram Choudhary | 21110138 | Contributed in training the tokenizer. |
| Vinay Goud       | 21110125 |                                  |
| Dhruv Patel      | 23210035 | Contributed in training the model.     |


